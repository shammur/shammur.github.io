---
layout: about
title: Home
permalink: /
subtitle: "Conversational AI | Representation Learning | Spoken Language Processing | Natural Language Processing"

profile:
  align: right
  image: Shammur_Chowdury_1.jpg
  # image_circular: true
news: true
# social: true # includes social icons at the bottom of the page
---

<!-- <br> -->
<!-- <hr style="border: none; border-top: 2px solid grey; margin: 20px 0;"> -->
<span class="research-dark-highlight"> âŒœâŒŸ Research Scientist</span>, Qatar Computing Research Institute (QCRI)

<span class="research-dark-highlight"> ğŸ—¨ï¸ Contact: </span> shchowdhury@hbku.edu.qa

<span class="research-dark-highlight">âœ Research Interest and Expertise:</span>

- <span class="research-highlight">Speech Processing: </span>
  Representation Learning, Self-Supervised Models, Atypical Human Interaction, Speech Discourse & Turn-taking, and Spoken Language Understanding.

- <span class="research-highlight">Natural Language Processing:</span>
 (Large) Language Models and their task understanding capabilities, Benchmarking.
  <!-- Large Language Models and their multilingual and diaclectal task understanding capabilities. -->

- <span class="research-highlight">Explainable and Inclusive Speech Technology:</span>  
  Dialectal and Accented Speech Recognition, Pronunciation Assessment, Children Speech Recognition, Multilingual Models.

<!-- <hr style="border: none; border-top: 2px solid grey; margin: 20px 0;"> -->

<!-- I am a Research Scientist at **Qatar Computing Research Institute (QCRI)**.  -->

<!-- My research interest encompasses **multilingual**, **multimodal**, and **multiview representation learning** for designing **Conversational AI** models.  -->

<!-- ğŸ’  I specilize in designing models that addresses complex challenges such as multispeaker interactions, nuanced multilingual and dialect variations, and code-switching, among various other intricate conversational dynamics. -->

<!-- I specialize in designing Conversational AI models, primarily addressing complex challenges such as multispeaker interactions, nuanced multilingual and dialect variations, and code-switching, among various other intricate conversational dynamics. -->

<!-- ğŸ”º I am currently leading (PI) the [QVoice]([https://link-url-here.org](http://qvoice.qcri.org)) project, which empowers speakersâ€”both native and non-native, children, and adults alikeâ€”to learn spoken Arabic, leveraging large multimodal AI models. -->

<!-- I have received numerous awards and grants, including the NVIDIA Academic Hardware Grant for my research in Simulating human language learning capabilities using DNN-based language models, a study that was also conducted as a part of the TRAILs project, funded by PRIN MIUR. As a key contributor to the EU-funded projects SENSEI and PortDial, I developed conversational models adept at understanding human conversation, facilitating automatic summarization and mental health screening. -->

<!-- ğŸ“š I authored over 60 peer-reviewed publications in top-tier conferences and journals and played an active role in the research community by organizing shared tasks, challenges, and workshops, as well as serving on the committees of top-tier conferences and special interest groups. -->

<!-- ğŸ› ï¸ I co-founded the Bangla Language Processing ([BNLP]([http://banglanlp.org])) Community and [MyVoice]([http://myvoice.arabicspeech.org]), a crowdsourced platform, designed to bridge the gaps between standard and dialectal Arabic resources. I am also maintaining the [ArabicSpeech]([http://arabicspeech.org]) Portal. -->



---

<div style="text-align: left; margin-top: 20px;">
  <a href="assets/pdf/SAC_CV_format2.pdf" target="_blank" style="text-decoration: none;">
    <img src="assets/img/cv_icon.png" alt="View PDF" width="40" style="vertical-align: middle; margin-right: 10px;">
    <span style="font-size: 18px; font-weight: bold;">View PDF</span>
  </a>
</div>
<br>
<!-- <hr style="border: none; border-top: 2px solid grey; margin: 20px 0;"> -->
<span class="research-dark-highlight">ğŸ‘ï¸â€ğŸ—¨ï¸ Short Bio:</span> 

Dr. Chowdhury specializes in designing Conversational AI models, primarily addressing complex challenges such as multispeaker interactions, nuanced multilingual and dialect variations, and code-switching, among various other intricate conversational dynamics. She is currently leading the speech technology development in Fanar â€” QCRI's Arabic Large Language Model project (sponsored by Qatar Government) â€” and serves as the Lead PI on both the NAVIA (funded by SRG3) and QVoice projects. 
<!-- The NAVIA project pioneers a holistic framework for early screening and intervention for Autism Spectrum Disorder (ASD) by integrating multimodal AI technologies. The QVoice project empowers both native and non-native speakers of all ages to learn spoken Arabic through adaptive speech technologies and multimodal feedback systems. -->
<!-- Dr. Chowdhury has received numerous awards and grants, including the SRG Grant for her research on simulating human language learning using deep neural network-based language models, a study also supported by the TRAILs project funded by PRIN MIUR. She has been a key contributor to EU-funded projects such as SENSEI and PortDial, where she developed conversational models for understanding human dialogue, automatic summarization, and mental health screening. -->
She has authored over 60 peer-reviewed publications in top-tier conferences and journals and is deeply engaged in the research community through organizing shared tasks, challenges, and workshops, and serving on the committees of leading conferences and special interest groups. She is also the co-founder of the Bangla Language Processing Community and MyVoice, a crowdsourced platform aimed at bridging the gap between standard and dialectal Arabic language resources.

<br>
<span class="research-dark-highlight">ğŸ§© Current Projects:</span> 
- <ul class="inline-list">
  <li><a href="https://fanar.qa/en" target="_blank" style="color: inherit; text-decoration: none;"><img src="assets/img/fanar.png" alt="Logo" style="height: 20px; vertical-align: middle; margin-right: 5px;"> Fanar </a></li> 

  <li><a href="" target="_blank" style="color: inherit; text-decoration: none;"> 
  <img src="assets/img/aura.png" alt="Logo" style="height: 30px; vertical-align: middle; margin-right: 5px;">
  AURA </a></li> 

  <li><a href="" target="_blank" style="color: inherit; text-decoration: none;">
  <img src="assets/img/RA_logo.png" alt="Logo" style="height: 30px; vertical-align: middle; margin-right: 5px;">
   NAVIA </a></li> 

  <li> <a href="http://qvoice.qcri.org" target="_blank" style="color: inherit; text-decoration: none;"> <img src="assets/img/QV_logo_icon_app.png" alt="Logo" style="height: 30px; vertical-align: middle; margin-right: 5px;">
 QVoice </a> </li>

  <li><a href="https://github.com/qcri/LLMeBench" target="_blank" style="color: inherit; text-decoration: none;"> 
  <img src="assets/img/LLemebench.png" alt="Logo" style="height: 30px; vertical-align: middle; margin-right: 5px;">
  LLMeBench </a></li> 

<!-- <span class="research-dark-highlight">ğŸ•°ï¸ Past Projects:</span>  -->

<span class="research-dark-highlight"> ğŸŒ Platforms:</span> 
- <ul class="inline-list">
  <li> <a href="http://banglanlp.org" target="_blank" style="color: inherit; text-decoration: none;"> <img src="assets/img/bnlp_logo.png" alt="Logo" style="height: 20px; vertical-align: middle; margin-right: 5px;">
   BNLP </a> </li>
  <li><a href="https://fanar.qa/en" target="_blank" style="color: inherit; text-decoration: none;"><img src="assets/img/as_icon.png" alt="Logo" style="height: 20px; vertical-align: middle; margin-right: 5px;"> ArabicSpeech </a></li> 

<br>
<!-- Download CV Button -->
<!-- <div style="text-align: left; margin-top: 20px;">
  <a href="assets/pdf/SAC_CV_format2.pdf" download style="text-decoration: none;">
    <img src="assets/img/cv_icon.png" alt="Download CV" width="40" style="vertical-align: left; margin-right: 10px;">
    <span style="font-size: 18px; font-weight: bold;">Download CV</span>
  </a>
</div>
 -->


<!-- Dr. Chowdhury specializes in designing Conversational AI models, primarily addressing complex challenges such as multispeaker interactions, nuanced multilingual and dialect variations, and code-switching, among various other intricate conversational dynamics. She is currently the leading the speech technology in Fanar - Arabic AI Large Language Model and also LPI on the NAVIA and QVoice project, which empowers speakersâ€”both native and non-native of all ages alikeâ€”to learn spoken Arabic. 
<!-- The QVoice project leverages adaptive speech technologies and multimodal feedback modules as its underlying technologies.  -->
<!-- Dr. Chowdhury has received numerous awards and grants, including the NVIDIA Academic Hardware Grant for her research in simulating human language learning capabilities using DNN-based language models, a study that was also conducted as a part of the TRAILs project, funded by PRIN MIUR. As a key contributor to the EU-funded projects SENSEI and PortDial, Dr. Chowdhury developed conversational models adept at understanding human conversation, facilitating automatic summarization and mental health screening. She authored over 60 peer-reviewed publications in top-tier conferences and journals and played an active role in the research community by organizing shared tasks, challenges, and workshops, as well as serving on the committees of top-tier conferences and special interest groups. She co-founded the Bangla Language Processing Community and MyVoice, a crowdsourced platform, designed to bridge the gaps between standard and dialectal Arabic resources.  --> 

<!-- <br><br> -->
<!-- <hr style="border: none; border-top: 2px solid grey; margin: 20px 0;"> -->
